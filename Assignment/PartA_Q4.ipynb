{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint,LearningRateScheduler\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "import os\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "import random \n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./full.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['filename'].str.split('_').str[-2]\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['label','filename']\n",
    "\n",
    "def split_dataset(df, columns_to_drop, test_size, random_state):\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "  df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "  df_train, df_test = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "\n",
    "  df_train2 = df_train.drop(columns_to_drop,axis=1)\n",
    "  y_train2 = df_train['label'].to_numpy()\n",
    "\n",
    "  df_test2 = df_test.drop(columns_to_drop,axis=1)\n",
    "  y_test2 = df_test['label'].to_numpy() \n",
    "\n",
    "  return df_train2, y_train2, df_test2, y_test2\n",
    "\n",
    "def preprocess_dataset(df_train, df_test):\n",
    "\n",
    "  standard_scaler = preprocessing.StandardScaler()\n",
    "  df_train_scaled = standard_scaler.fit_transform(df_train)\n",
    "\n",
    "  df_test_scaled = standard_scaler.transform(df_test)\n",
    "\n",
    "  return df_train_scaled, df_test_scaled\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_dataset(df, columns_to_drop, test_size=0.3, random_state=0) # positive labels being encoded as 1\n",
    "\n",
    "X_train_scaled, X_test_scaled = preprocess_dataset(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_voice_record_df = pd.read_csv('Q4_neg_voice_record.csv')\n",
    "pos_voice_record_df = pd.read_csv('Q4_pos_voice_record.csv')\n",
    "threshold = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_voice_record_df = neg_voice_record_df.drop([\"filename\"],axis = 1)\n",
    "pos_voice_record_df = pos_voice_record_df.drop([\"filename\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(df_train, df_test):\n",
    "    \n",
    "  standard_scaler = preprocessing.StandardScaler()\n",
    "  df_train_scaled = standard_scaler.fit_transform(df_train)\n",
    "\n",
    "  df_test_scaled = standard_scaler.transform(df_test)\n",
    "\n",
    "  return df_test_scaled\n",
    "\n",
    "\n",
    "neg_voice_record_df_scaled = process_dataset(X_train, neg_voice_record_df)\n",
    "pos_voice_record_df_scaled = process_dataset(X_train, pos_voice_record_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4B \n",
    "**Do a model prediction on your sample test dataset with threshold = 0.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_model = keras.models.load_model('optimized_model/')\n",
    "\n",
    "neg_result_label = (optimized_model.predict(neg_voice_record_df_scaled)>threshold).astype(\"int32\")\n",
    "pos_result_label = (optimized_model.predict(pos_voice_record_df_scaled)>threshold).astype(\"int32\")\n",
    "\n",
    "data = {\"Label\": [\"Negative Voice \", \"Positive Voice\"],\"Result\":[neg_result_label, pos_result_label]}\n",
    "\n",
    "\n",
    "data_df = pd.DataFrame.from_dict(data)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4C\n",
    "#### Identify most important features using SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve 1000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample = X_train_scaled[np.random.choice(len(X_train_scaled), 1000, replace=False)]\n",
    "X_test_sample = X_test_scaled[np.random.choice(len(X_test_scaled), 1000, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('optimized_model/')\n",
    "explainer = shap.DeepExplainer(model , X_train_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Force plot of neg voice record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(neg_voice_record_df_scaled)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0][0], features = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary plot of neg voice record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[0], plot_type = 'bar', feature_names = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Force plot of pos voice record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(pos_voice_record_df_scaled)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0][0], features = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary plot of pos voice record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[0], plot_type = 'bar', feature_names = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "**From the force plot of both the pos and neg_voice record, it shows the top most influential features that led to prediction value indicated. The red color features influence positivity(towards the predicted value) and the blue color influence negativity(away from the predicted value). With the force plot and summary, we can identify the magnitude of the features' impact to the resulting predicted value,**\n",
    "\n",
    "#### Analysis on Positive Voice Record\n",
    "\n",
    "**In the positive voice recording, we can identify that the features in red(mfcc3_mean, mfcc10_mean, mfcc0_var, mfcc10_var, perc_mean) to be the most influential features in influencing the prediction to be closer to 1 (positive label) and in blue(mfcc3_var, mfcc7_mean, mfcc12_mean, mfcc8_mean, mfcc9_var) are the most influential features in influencing the predict to be closer to 0 (negative label)**\n",
    "\n",
    "**From the summary plot, we can then identify the magnitude of the the features' impact to the resulting predicted value**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion Points\n",
    "\n",
    "#### 1. Limitations of FFN\n",
    "\n",
    "**FFN is prone to overfitting and with given large number of parameters, the model will be more complex and could take a long time to train. In addition, due to the risk of overfitting, the model may lose the ability to generalize to new examples.**\n",
    "\n",
    "**Also, feed-forward neural networks may have results that are difficult to interpret due to the complexitiy of the model's architecture.**\n",
    "\n",
    "\n",
    "#### 2. Most impactful parameter\n",
    "\n",
    "**In terms of time taken for every epochï¼Œthe batch size is the most impactful parameter as from the table at Q2b, we notice that doubling the batch size shorterns the time taken for the final epoch significantly.**\n",
    "\n",
    "**In terms of accuracy, the number of neurons in the first hidden layer is the most impactful paramater as from the table at Q3b, we notice that there is significant rise in accuracy when the number of neurons increases**\n",
    "\n",
    "#### 3. Alternative approaches\n",
    "\n",
    "**We can use CNN model architecture for genre classfication as well. Similar to the assignment, we have to perform feature extraction and define the model architecture. In fact, we can experiment by adding more hidden layers so that the model is able to handle more complex tasks and learn the relationships between features**\n",
    "\n",
    "#### 4. Other dataset\n",
    "\n",
    "**Analysing the audio waveforms to idenitify the species of the subject(animals). Perhaps more hidden layer is required for the model to learn the relationship between the features extracted from the audio of different species** \n",
    "\n",
    "**Also, we can do speech enhancement. To improve the quality of the audio, we would need a very large and complex and neural network model which would need an increase in hidden layers and number of units.**\n",
    "\n",
    "\n",
    "#### 5. Neural Network Ensemble\n",
    "\n",
    "**An ensemble of neural network can be done to achieve diversification in order to build models that can generalize better**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e20b04dd985343179d8656fb1930f451adca8610422f13b5e4759b9499c407bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
